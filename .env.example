# vLLM Service Configuration
MODEL_PATH=TheBloke/Mistral-7B-Instruct-v0.2-AWQ
GPU_MEMORY_UTILIZATION=0.9
MAX_NUM_SEQS=32
BLOCK_SIZE=16
SWAP_SPACE=4
QUANTIZATION=awq
DTYPE=float16
MAX_CONTEXT_LEN=4096

# Service Configuration
HOST=0.0.0.0
PORT=8080
LOG_LEVEL=INFO

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Prometheus Configuration
PROMETHEUS_PORT=9090
METRICS_PATH=/metrics

# Optional: Redis Cache
REDIS_HOST=redis
REDIS_PORT=6379
ENABLE_CACHE=false
