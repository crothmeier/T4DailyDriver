services:
  vllm:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - CUDA_VERSION=12.4
    image: vllm-service:cuda124
    container_name: vllm-t4-service
    ports:
      - "8080:8080"
    environment:
      - MODEL_PATH=TheBloke/Mistral-7B-Instruct-v0.2-AWQ
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_HOME=/cache/hf
      - VLLM_WORKDIR=/cache/vllm
      - VLLM_ATTENTION_BACKEND=SDPA  # T4-optimized backend
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
        limits:
          memory: 32G
          cpus: '8'
    # Security: Read-only root filesystem with explicit writable mounts
    read_only: true
    tmpfs:
      - /tmp:size=256m  # Runtime temp files (safe: limited size, memory-backed)
    volumes:
      - ./cache/hf:/cache/hf:rw  # HuggingFace cache (safe: required for model downloads)
      - ./cache/vllm:/cache/vllm:rw  # vLLM working directory (safe: required for vLLM operations)
      - ./cache/config:/home/vllm/.config:rw  # User config directory (safe: required for vLLM usage reporter)
      - ./logs:/app/logs:rw  # Application logs (safe: required for observability)
    # Security: Drop all capabilities except those needed for service operation
    cap_drop:
      - ALL  # Drop all capabilities first
    restart: unless-stopped
    networks:
      - vllm-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/ready || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 30  # Try for 10 minutes (30 * 20s)
      start_period: 300s  # Give 5 minutes for model loading

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    # Security: Read-only root filesystem with explicit writable mount
    read_only: true
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro  # Config (safe: read-only mount)
      - prometheus-data:/prometheus:rw  # TSDB storage (safe: required for metrics storage)
    tmpfs:
      - /tmp:size=100M  # Runtime temp files (safe: limited size for scrape processing)
    # Security: Drop unnecessary capabilities
    cap_drop:
      - ALL  # Drop all capabilities first
    cap_add:
      - DAC_OVERRIDE  # Bypass file permissions (safe: needed for container user access)
      # NET_RAW removed - not needed for HTTP scraping
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - vllm-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    # Security: Read-only root filesystem with explicit writable mounts
    read_only: true
    volumes:
      - grafana-data:/var/lib/grafana:rw  # Data storage (safe: required for dashboards/users)
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro  # Dashboards (safe: read-only)
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro  # Datasources (safe: read-only)
    tmpfs:
      - /tmp:size=100M  # Runtime temp files (safe: limited size for dashboard rendering)
    # Security: Drop unnecessary capabilities
    cap_drop:
      - ALL  # Drop all capabilities first
    cap_add:
      - CHOWN  # File ownership changes (safe: needed for data dir initialization)
      - DAC_OVERRIDE  # Bypass file permissions (safe: needed for container user access)
      - SETUID  # Change process UID (safe: needed for user switching)
      - SETGID  # Change process GID (safe: needed for group switching)
      # NET_RAW removed - not needed for HTTP service
    networks:
      - vllm-network
    restart: unless-stopped
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s

  # NVIDIA DCGM Exporter for GPU metrics
  dcgm-exporter:
    image: nvidia/dcgm-exporter:3.1.7-3.1.4-ubuntu20.04
    container_name: dcgm-exporter
    ports:
      - "9400:9400"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    # Security: Read-only root filesystem
    read_only: true
    tmpfs:
      - /tmp:size=50M  # Runtime temp files (safe: limited size for metrics collection)
    # Security: Drop unnecessary capabilities
    cap_drop:
      - ALL  # Drop all capabilities first
    cap_add:
      - DAC_OVERRIDE  # Bypass file permissions (safe: needed for GPU device access)
      # NET_RAW removed - not needed for metrics export
    networks:
      - vllm-network
    restart: unless-stopped

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    # Security: Read-only root filesystem with explicit writable mount
    read_only: true
    volumes:
      - redis-data:/data:rw  # Persistent storage (safe: required for cache persistence)
    tmpfs:
      - /tmp:size=64m  # Runtime temp files (safe: limited size for Redis operations)
    # Security: Drop unnecessary capabilities
    cap_drop:
      - ALL  # Drop all capabilities first
    cap_add:
      - SETUID  # Redis needs this to switch users
      - SETGID  # Redis needs this to switch groups
    networks:
      - vllm-network
    restart: unless-stopped
    command: redis-server --save 60 1 --save 300 10 --save 900 50
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep -q PONG"]
      interval: 15s
      timeout: 3s
      retries: 5
      start_period: 30s

volumes:
  prometheus-data:
  grafana-data:
  redis-data:

networks:
  vllm-network:
    driver: bridge
